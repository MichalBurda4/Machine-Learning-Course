# -*- coding: utf-8 -*-
"""lab04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UxaKuCH-cKk-IvnGJFjqtZtERB6CAuCK
"""

import numpy as np
from sklearn import datasets
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle

"""**Przygotowanie danych dla klasyfikacji**

"""

from sklearn import datasets

data_breast_cancer = datasets.load_breast_cancer(as_frame=False)
print(data_breast_cancer['DESCR'])

data_iris = datasets.load_iris()
print(data_iris['DESCR'])



"""**Klasyfikacja**

1. Podziel zbiór danych na uczący i testujący w proporcjach 80/20.
2. Zbuduj modele klasyfikacji SVM dla średnich (mean) wartości cech area oraz smoothness;
stwórz dwa modele:
1. LinearSVC, z funkcją straty “hinge”,
2. LinearSVC, z funkcją straty “hinge”, po uprzednim automatycznym skalowaniu wartości
cech.
3. Policz dokładność (accuracy) dla ww. klasyfikacji osobno na zbiorze uczącym i testują5
cym, zapisz wartości na liście w kolejności: zbiór uczący bez skalowania, zbiór testujący
bez skalowania, zbiór uczący ze m, zbiór testujący ze skalowaniem. Listę zapisz w pliku
Pickle bc_acc.pkl.
4 pkt.
4. Czy skalowanie coś dało?
5. Ekperyment powtórz dla zbioru irysów; zbuduj model wykrywający, czy dany przypadek jest
gatunku Virginica na podstawie cech: długość i szerokość płatka.
6. Policz dokładność (accuracy) dla w/w klasyfikacji osobno na zbiorze uczącym i testującym, zapisz wartości na liście w kolejności: zbiór uczący bez skalowania, zbiór testujący bez skalowania, zbiór uczący ze skalowanie, zbiór testujący ze skalowaniem. W.w. listę zapisz w pliku
Pickle iris_acc.pkl.
4 pkt.
7. Czy skalowanie coś dało?
"""

# Załaduj zbiory danych
data_breast_cancer = datasets.load_breast_cancer(as_frame=False)
data_iris = datasets.load_iris()

# 1.Podziel zbiór danych na uczący i testujący w proporcjach 80/20.
X_bc_train, X_bc_test, y_bc_train, y_bc_test = train_test_split(data_breast_cancer.data[:, [0, 1]], data_breast_cancer.target, test_size=0.2, random_state=42)
X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(data_iris.data[:, [2, 3]], (data_iris.target == 2).astype(int), test_size=0.2, random_state=42)

# Zdefiniuj modele
models = [
    LinearSVC(loss='hinge'),
    LinearSVC(loss='hinge'),
]

# Trenuj modele na danych bez skalowania
for model in models:
    model.fit(X_bc_train, y_bc_train)

# Oblicz dokładność na danych bez skalowania
bc_accuracy_no_scaling = []
for model in models:
    train_preds = model.predict(X_bc_train)
    test_preds = model.predict(X_bc_test)
    bc_accuracy_no_scaling.append(accuracy_score(y_bc_train, train_preds))
    bc_accuracy_no_scaling.append(accuracy_score(y_bc_test, test_preds))

# Stwórz i dopasuj model na danych ze skalowaniem
scaler = StandardScaler()
X_bc_train_scaled = scaler.fit_transform(X_bc_train)
X_bc_test_scaled = scaler.transform(X_bc_test)

models_scaled = [
    LinearSVC(loss='hinge'),
    LinearSVC(loss='hinge'),
]

for model in models_scaled:
    model.fit(X_bc_train_scaled, y_bc_train)

# Oblicz dokładność na danych ze skalowaniem
bc_accuracy_with_scaling = []
for model in models_scaled:
    train_preds = model.predict(X_bc_train_scaled)
    test_preds = model.predict(X_bc_test_scaled)
    bc_accuracy_with_scaling.append(accuracy_score(y_bc_train, train_preds))
    bc_accuracy_with_scaling.append(accuracy_score(y_bc_test, test_preds))

# Zapisz wyniki do pliku pickle
with open('bc_acc.pkl', 'wb') as f:
    pickle.dump(bc_accuracy_no_scaling + bc_accuracy_with_scaling, f)

# Ekperyment dla zbioru irysów
models_iris = [
    LinearSVC(loss='hinge'),
    LinearSVC(loss='hinge'),
]

for model in models_iris:
    model.fit(X_iris_train, y_iris_train)

iris_accuracy_no_scaling = []
for model in models_iris:
    train_preds = model.predict(X_iris_train)
    test_preds = model.predict(X_iris_test)
    iris_accuracy_no_scaling.append(accuracy_score(y_iris_train, train_preds))
    iris_accuracy_no_scaling.append(accuracy_score(y_iris_test, test_preds))

scaler_iris = StandardScaler()
X_iris_train_scaled = scaler_iris.fit_transform(X_iris_train)
X_iris_test_scaled = scaler_iris.transform(X_iris_test)

models_iris_scaled = [
    LinearSVC(loss='hinge'),
    LinearSVC(loss='hinge'),
]

for model in models_iris_scaled:
    model.fit(X_iris_train_scaled, y_iris_train)

iris_accuracy_with_scaling = []
for model in models_iris_scaled:
    train_preds = model.predict(X_iris_train_scaled)
    test_preds = model.predict(X_iris_test_scaled)
    iris_accuracy_with_scaling.append(accuracy_score(y_iris_train, train_preds))
    iris_accuracy_with_scaling.append(accuracy_score(y_iris_test, test_preds))

with open('iris_acc.pkl', 'wb') as f:
    pickle.dump(iris_accuracy_no_scaling + iris_accuracy_with_scaling, f)

"""**4 Przygotowanie danych dla regresji**
1. Użyj tej samej funkcji co z laboratorium o regresji
"""

import numpy as np
import pandas as pd
size = 900
X = np.random.rand(size)*5-2.5
w4, w3, w2, w1, w0 = 1, 2, 1, -4, 2
y = w4*(X**4) + w3*(X**3) + w2*(X**2) + w1*X + w0 + np.random.randn(size)*8-4
df = pd.DataFrame({'x': X, 'y': y})
df.plot.scatter(x='x',y='y')

"""2. Podziel zbiór uczący i testowy w proporcji 80:20.

"""

from sklearn.model_selection import train_test_split

# Podział zbioru danych na uczący i testowy w proporcji 80:20
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Wyświetlenie rozmiarów zbiorów uczącego i testowego
print("Rozmiar zbioru uczącego:", len(train_df))
print("Rozmiar zbioru testowego:", len(test_df))

"""**Regresja**
1. Zbuduj potok rozszerzający cechy do 4 wymiarów, za pomocą wielomianu 4 stopnia oraz
regresora LinearSVR z domyslnymi parametrami.
2. Oblicz MSE dla zbioru uczącego i zbioru testowego. Wyniki powinny być podobne do najlepszych rezultatów z ćwiczenia o regresji, lub nawet lepsze.
3. Powtórz uczenie dla regresora SVR z kernelem poly 4 stopnia i pozostałymi parametrami z
wartościami domyslnymi. Wyniki MSE powinny być … rozczarowujące.
4. Jakie hiperparametry użyć żeby SVR miał podobną jakość co LinearSVR? Użyj GridSearchCV na całym zbiorze danych (nie tylko uczącym!). Do znalezienia optymalnej pary
parametrów coef0 oraz C. Jak funkcje oceny zastosuj neg_mean_squared_error. Poszukaj
optymalnych wartości spośród: "C" : [0.1, 1, 10], "coef0" : [0.1, 1, 10].
5. Dla wyliczonych optymalnych wartości hiperparametrów przeprowadź proces uczenia SVR
raz jeszcze. Oblicz wyniki MSE dla zbioru uczącego i testowego.
6. Zapisz wyniki MSE z punktu 2 i 5 na liście (4 elementy), którą następnie zapisz w pliku Pickle
o nazwie: reg_mse.pkl.

"""

import numpy as np
import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.svm import LinearSVR, SVR
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV
import pickle

# Generowanie danych
size = 900
X = np.random.rand(size)*5-2.5
w4, w3, w2, w1, w0 = 1, 2, 1, -4, 2
y = w4*(X**4) + w3*(X**3) + w2*(X**2) + w1*X + w0 + np.random.randn(size)*8-4
df = pd.DataFrame({'x': X, 'y': y})

# Podział na zbiór uczący i testowy
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# Budowa potoku dla LinearSVR
linear_svr_pipeline = Pipeline([
    ('poly_features', PolynomialFeatures(degree=4)),
    ('linear_svr', LinearSVR())
])

# Uczenie i predykcja dla LinearSVR
linear_svr_pipeline.fit(train_df[['x']], train_df['y'])
train_preds_linear_svr = linear_svr_pipeline.predict(train_df[['x']])
test_preds_linear_svr = linear_svr_pipeline.predict(test_df[['x']])

# Obliczenie MSE dla LinearSVR
mse_train_linear_svr = mean_squared_error(train_df['y'], train_preds_linear_svr)
mse_test_linear_svr = mean_squared_error(test_df['y'], test_preds_linear_svr)

# Budowa potoku dla SVR z kernelem poly 4 stopnia
svr_pipeline = Pipeline([
    ('poly_features', PolynomialFeatures(degree=4)),
    ('svr', SVR(kernel='poly'))
])

# Uczenie i predykcja dla SVR
svr_pipeline.fit(train_df[['x']], train_df['y'])
train_preds_svr = svr_pipeline.predict(train_df[['x']])
test_preds_svr = svr_pipeline.predict(test_df[['x']])

# Obliczenie MSE dla SVR
mse_train_svr = mean_squared_error(train_df['y'], train_preds_svr)
mse_test_svr = mean_squared_error(test_df['y'], test_preds_svr)

# Użycie GridSearchCV dla SVR
param_grid = {'C': [0.1, 1, 10], 'coef0': [0.1, 1, 10]}
grid_search = GridSearchCV(SVR(kernel='poly', degree=4), param_grid, scoring='neg_mean_squared_error')
grid_search.fit(df[['x']], df['y'])

# Najlepsze parametry dla SVR
best_params = grid_search.best_params_

# Ponowne uczenie SVR z optymalnymi parametrami
best_svr_pipeline = Pipeline([
    ('poly_features', PolynomialFeatures(degree=4)),
    ('svr', SVR(kernel='poly', **best_params))
])

best_svr_pipeline.fit(train_df[['x']], train_df['y'])
train_preds_best_svr = best_svr_pipeline.predict(train_df[['x']])
test_preds_best_svr = best_svr_pipeline.predict(test_df[['x']])

# Obliczenie MSE dla SVR z optymalnymi parametrami
mse_train_best_svr = mean_squared_error(train_df['y'], train_preds_best_svr)
mse_test_best_svr = mean_squared_error(test_df['y'], test_preds_best_svr)

# Zapis wyników MSE do pliku pickle
mse_results = [mse_train_linear_svr, mse_test_linear_svr, mse_train_best_svr, mse_test_best_svr]
with open('reg_mse.pkl', 'wb') as f:
    pickle.dump(mse_results, f)