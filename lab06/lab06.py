# -*- coding: utf-8 -*-
"""lab06.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vqGSHWEfIQ9P08ZRrH3jGFj7fCtOn7C6

**1 Cel/Zakres**

• Metody zespołowe.

  – równoległe,

  – sekwencyjne.

• Hard/soft voting.

• Bagging.

• Boosting.

**2** Przygotowanie danych
```
from sklearn import datasets
data_breast_cancer = datasets.load_breast_cancer(as_frame=True)
```
"""

import pandas as pd
from sklearn import datasets
data_breast_cancer = datasets.load_breast_cancer(as_frame=True)

from sklearn.ensemble import VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import pickle

"""**3 Ćwiczenie**
Uwaga: stosuj domyślne wartości parametrów dla użytych klas, chyba, że z opisu danego ćwiczenia
wynika inaczej.
1. Podziel zbiór ‘data_breast_cancer’ na uczący i testujący w proporcjach 80:20.
2. Zbuduj ensemble używając klasyfikatorów binarnych, których używałeś(aś) w poprzednich
ćwiczeniach, tj.: drzewa decyzyjne, regresja logistyczna, k najbliższych sąsiadów, do klasyfikacji w oparciu o cechy: mean texture, mean symmetry. Użyj domyślnych parametrów.
3. Porównaj dokładność (accuracy) w/w klasyfikatorów z zespołem z głosowaniem typu hard
oraz soft.
4. Zapisz rezultaty jako listę par (dokładność_dla_zb_uczącego,
dokładność_dla_zb_testującego) dla każdego z w/w klasyfikatorów (razem 5 elementów)
i umieść ją w pliku Pickle o nazwie acc_vote.pkl
5 pkt
Zapisz klasyfikatory jako listę w pliku Pickle o nazwie vote.pkl (5 obiektów).
2 pkt
5. Wykonaj na zbiorze uczącym wykorzystując 30 drzew decyzyjnych:
• Bagging,
1
• Bagging z wykorzystaniem 50% instancji,
• Pasting,
• Pasting z wykorzystaniem 50% instancji, oraz
• Random Forest,
• AdaBoost,
• Gradient Boosting.
Dlaczego Random Forest daje inne rezultaty niż Bagging + drzewa decyzyjne?
6. Oblicz dokładności oraz zapisz je jako listę par (dokładność_dla_zb_uczącego,
dokładność_dla_zb_testującego) dla każdego z w/w estymatorów (razem 7 elementów)
w pliku Pickle o nazwie acc_bag.pkl.
7 pkt
Zapisz klasyfikatory jako listę w pliku Pickle o nazwie bag.pkl
2 pkt
7. Przeprowadź sampling 2 cech z wszystkich dostepnych bez powtórzeń z wykorzystaniem 30
drzew decyzyjnych, wybierz połowę instancji dla każdego z drzew z powtórzeniami.
8. Zapisz dokładności w/w estymatora jako listę : dokładność_dla_zb_uczącego,
dokładność_dla_zb_testującego w pliku Pickle acc_fea.pkl.
2 pkt
Zapisz klasyfikator jako jednoelementową listę w pliku Pickle o nazwie fea.pkl
1 pkt
9. Sprawdź, które cechy dają najwięszą dokładność. Dostęp do poszczególnych estymatorów,
aby obliczyć dokładność, możesz uzyskać za pomocą: BaggingClasifier.estimators_,
cechy wybrane przez sampling dla każdego z estymatorów znajdziesz w:
BaggingClassifier.estimators_features_. Zbuduj ranking estymatorów jako DataFrame,
który będzie mieć w kolejnych kolumnach: dokładność dla zb. uczącego, dokładnośc dla zb.
testującego, lista nazw cech. Każdy wiersz to informacje o jednym estymatorze. DataFrame
posortuj malejąco po wartościach dokładności dla zbioru testującego i uczącego oraz zapisz
w pliku Pickle o nazwie acc_fea_rank.pkl
5 pkt

"""

#1.Podziel zbiór ‘data_breast_cancer’ na uczący i testujący w proporcjach 80:20.
#Podział danych na zbiór testowy i treningowy
from sklearn.model_selection import train_test_split
X = data_breast_cancer.data[['mean texture', 'mean symmetry']]
y = data_breast_cancer.target
X_train, X_test, y_train, y_test = train_test_split(data_breast_cancer['data'][['mean texture', 'mean symmetry']], data_breast_cancer['target'], test_size=0.2)

#2 dobrze
decision_tree_clf = DecisionTreeClassifier()
logistic_regression_clf = SGDClassifier(loss='log_loss')
knn_clf = KNeighborsClassifier()

ensemble_hard = VotingClassifier(estimators=[('dt', decision_tree_clf),
                                          ('lr', logistic_regression_clf),
                                          ('knn', knn_clf)],
                              voting='hard')
ensemble_soft = VotingClassifier(estimators=[('dt', decision_tree_clf),
                                             ('lr', logistic_regression_clf),
                                             ('knn', knn_clf)],
                                 voting='soft')


ensemble_hard.fit(X_train, y_train)
ensemble_soft.fit(X_train, y_train)

#3 dobrze
# list of touples (accuracy for train, accuracy for test)
list_of_accuracy = []


# decision_tree_clf
list_of_accuracy.append((accuracy_score(y_train, decision_tree_clf.fit(X_train, y_train).predict(X_train)),
                         accuracy_score(y_test, decision_tree_clf.fit(X_train, y_train).predict(X_test))))

# logistic_regression_clf
list_of_accuracy.append((accuracy_score(y_train, logistic_regression_clf.fit(X_train, y_train).predict(X_train)),
                         accuracy_score(y_test, logistic_regression_clf.fit(X_train, y_train).predict(X_test))))

# knn_clf
list_of_accuracy.append((accuracy_score(y_train, knn_clf.fit(X_train, y_train).predict(X_train)),
                         accuracy_score(y_test, knn_clf.fit(X_train, y_train).predict(X_test))))

# ensemble_hard
list_of_accuracy.append((accuracy_score(y_train, ensemble_hard.predict(X_train)),
                         accuracy_score(y_test, ensemble_hard.predict(X_test))))

# ensemble_soft
list_of_accuracy.append((accuracy_score(y_train, ensemble_soft.predict(X_train)),
                         accuracy_score(y_test, ensemble_soft.predict(X_test))))

# save to pickle
with open('acc_vote.pkl', 'wb') as f:
    pickle.dump(list_of_accuracy, f)

for pair in list_of_accuracy:
    print('train: {:.5f}, test: {:.5f}'.format(pair[0], pair[1]))

# List of tuples (accuracy for train, accuracy for test)
list_of_accuracy = []

# Decision Tree Classifier
train_accuracy_dt = accuracy_score(y_train, decision_tree_clf.fit(X_train, y_train).predict(X_train))
test_accuracy_dt = accuracy_score(y_test, decision_tree_clf.predict(X_test))
list_of_accuracy.append((train_accuracy_dt, test_accuracy_dt))

# Logistic Regression Classifier
train_accuracy_lr = accuracy_score(y_train, logistic_regression_clf.fit(X_train, y_train).predict(X_train))
test_accuracy_lr = accuracy_score(y_test, logistic_regression_clf.predict(X_test))
list_of_accuracy.append((train_accuracy_lr, test_accuracy_lr))

# KNN Classifier
train_accuracy_knn = accuracy_score(y_train, knn_clf.fit(X_train, y_train).predict(X_train))
test_accuracy_knn = accuracy_score(y_test, knn_clf.predict(X_test))
list_of_accuracy.append((train_accuracy_knn, test_accuracy_knn))

# Ensemble (Hard)
train_accuracy_ensemble_hard = accuracy_score(y_train, ensemble_hard.predict(X_train))
test_accuracy_ensemble_hard = accuracy_score(y_test, ensemble_hard.predict(X_test))
list_of_accuracy.append((train_accuracy_ensemble_hard, test_accuracy_ensemble_hard))

# Ensemble (Soft)
train_accuracy_ensemble_soft = accuracy_score(y_train, ensemble_soft.predict(X_train))
test_accuracy_ensemble_soft = accuracy_score(y_test, ensemble_soft.predict(X_test))
list_of_accuracy.append((train_accuracy_ensemble_soft, test_accuracy_ensemble_soft))

# Save to pickle
with open('acc_vote.pkl', 'wb') as f:
    pickle.dump(list_of_accuracy, f)

# Print results without loop
print('Train accuracy (Decision Tree): {:.5f}, Test accuracy (Decision Tree): {:.5f}'.format(list_of_accuracy[0][0], list_of_accuracy[0][1]))
print('Train accuracy (Logistic Regression): {:.5f}, Test accuracy (Logistic Regression): {:.5f}'.format(list_of_accuracy[1][0], list_of_accuracy[1][1]))
print('Train accuracy (KNN): {:.5f}, Test accuracy (KNN): {:.5f}'.format(list_of_accuracy[2][0], list_of_accuracy[2][1]))
print('Train accuracy (Ensemble Hard): {:.5f}, Test accuracy (Ensemble Hard): {:.5f}'.format(list_of_accuracy[3][0], list_of_accuracy[3][1]))
print('Train accuracy (Ensemble Soft): {:.5f}, Test accuracy (Ensemble Soft): {:.5f}'.format(list_of_accuracy[4][0], list_of_accuracy[4][1]))

#4
# list of classifiers
list_of_clf = [decision_tree_clf, logistic_regression_clf, knn_clf, ensemble_hard, ensemble_soft]
with open('vote.pkl', 'wb') as f:
    pickle.dump(list_of_clf, f)

#5 dobrze
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier

base_clf = DecisionTreeClassifier(random_state=42)

classifiers = [
    BaggingClassifier(base_clf, n_estimators=30, random_state=42),  # Bagging
    BaggingClassifier(base_clf, n_estimators=30, max_samples=0.5, random_state=42),  # Bagging (max_samples=0.5)
    BaggingClassifier(base_clf, n_estimators=30, bootstrap=False, random_state=42),  # Pasting
    BaggingClassifier(base_clf, n_estimators=30, max_samples=0.5, bootstrap=False, random_state=42),  # Pasting (max_samples=0.5)
    RandomForestClassifier(n_estimators=30, random_state=42),  # Random Forest
    AdaBoostClassifier(base_clf, n_estimators=30, random_state=42),  # AdaBoost
    GradientBoostingClassifier(n_estimators=30, random_state=42)  # Gradient Boosting
]

#6 dobrze
import pickle

# Lista wyników dokładności dla klasyfikatorów
accuracy_results = []

# Dopasowanie modeli i obliczenie dokładności
for clf in classifiers:
    clf.fit(X_train, y_train)

    # Dokładność dla danych treningowych
    train_acc = accuracy_score(y_train, clf.predict(X_train))

    # Dokładność dla danych testowych
    test_acc = accuracy_score(y_test, clf.predict(X_test))

    # Dodanie wyników do listy
    accuracy_results.append((train_acc, test_acc))

# Zapisanie wyników dokładności do pliku
with open('acc_bag.pkl', 'wb') as f:
    pickle.dump(accuracy_results, f)

# Zapisanie klasyfikatorów do pliku
with open('bag.pkl', 'wb') as f:
    pickle.dump(classifiers, f)

accuracy_results

classifiers

#7 8
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=30, bootstrap=True, bootstrap_features=True, max_samples=0.5, max_features=2)
bag_clf.fit(X_train, y_train)

save_list_acc_fea = []

bag_fea_acc_train = accuracy_score(y_train, bag_clf.predict(X_train))
bag_fea_acc_test = accuracy_score(y_test, bag_clf.predict(X_test))
save_list_acc_fea.append(bag_fea_acc_train)
save_list_acc_fea.append(bag_fea_acc_test)

with open('acc_fea.pkl', 'wb') as f:
  pickle.dump(save_list_acc_fea, f)

clf_list = []
clf_list.append(bag_clf)

with open('fea.pkl', 'wb') as f:
  pickle.dump(clf_list, f)

import pandas as pd

# Utworzenie pustej ramki danych, w której będziemy przechowywać wyniki
df = pd.DataFrame(columns=['train', 'test', 'features'])

# Iteracja przez każdy estymator i odpowiadające mu cechy
for estimator, features in zip(bag_clf.estimators_, bag_clf.estimators_features_):
    # Obliczenie dokładności dla danych treningowych przy użyciu estymatora
    est_acc_train = accuracy_score(y_train, estimator.predict(X_train))

    # Obliczenie dokładności dla danych testowych przy użyciu estymatora
    est_acc_test = accuracy_score(y_test, estimator.predict(X_test))

    # Dodanie wyników do ramki danych
    df.loc[len(df)] = {'train': est_acc_train, 'test': est_acc_test, 'features': features}

# Posortowanie wyników w ramce danych według dokładności testowej, a w przypadku takiej samej dokładności - według dokładności treningowej
df = df.sort_values(by=['test', 'train'], ascending=False)

# Zapisanie ramki danych z wynikami do pliku
df.to_pickle('acc_fea_rank.pkl')

df