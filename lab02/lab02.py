# -*- coding: utf-8 -*-
"""lab02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m_j_iwK4RVFzjipW70UxpoVA48t5UBZ2
"""

#zad2

import numpy as np

from sklearn.datasets import fetch_openml
mnist = fetch_openml('mnist_784', version=1)

# Sprawdzenie dostępnych atrybutów obiektu
print("Atrybuty dostępne w obiekcie mnist:")
print(mnist.keys())

# Sprawdzenie kształtu cech (features)
print("Kształt cech (features):", mnist.data.shape)

# Sprawdzenie kształtu etykiet (labels)
print("Kształt etykiet (labels):", mnist.target.shape)

print((np.array(mnist.data.loc[42]).reshape(28, 28) > 0).astype(int))

#zad3

#Tabela Dla wygody utwórz osobne DataFrame’y z cechami i etykietami (nazwij je na przykład X i y).
X = mnist["data"] #dane
y = mnist["target"].astype(np.uint8) #cel

y.sort_values(inplace=True) #sortujemy y rosnąco
X.reindex(y.index) #Posortuj identycznie zbiór X wykorzystując funkcję reindex.

import pandas as pd

# Tworzenie osobnych DataFrame'ów z cechami (X) i etykietami (y)
X = pd.DataFrame(mnist.data)
y = pd.Series(mnist.target)

# Sortowanie zbioru etykiet rosnąco
y_sorted = y.sort_values()

# Sortowanie zbioru cech zgodnie z posortowanymi etykietami
X_sorted = X.reindex(y_sorted.index)

# Podział danych na zbiory uczący i testowy w proporcjach 80-20
X_train, X_test = X_sorted[:56000], X_sorted[56000:]
y_train, y_test = y_sorted[:56000], y_sorted[56000:]

print("Rozmiary zbiorów uczącego i testowego:")
print("X_train:", X_train.shape, "y_train:", y_train.shape)
print("X_test:", X_test.shape, "y_test:", y_test.shape)
print(np.unique(y_train), np.unique(y_test))

from sklearn.model_selection import train_test_split

# Użycie funkcji train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_sorted, y_sorted, test_size=0.2, random_state=42)

print("Klasy w zbiorze y_train:", sorted(y_train.unique()))
print("Klasy w zbiorze y_test:", sorted(y_test.unique()))

#Teraz przeprowadź przy pomocy tej samej funkcji dzielenie zbiorów tak, aby wybór próbek w
#obu zbiorach był losowy (cały czas zachowując proporcje 80/20). Sprawdź klasy w obu zbiorach.

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)
print(np.unique(y_train), np.unique(y_test))

#zad4

X = mnist["data"]
y = mnist["target"].astype(np.uint8)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)

y_train_0 = (y_train == 0)
y_test_0 = (y_test == 0)
print(np.unique(y_train_0))

#Tworzy klasyfikator SGD (Stochastic Gradient Descent) o nazwie sgd_clf_0 i uczony jest na danych treningowych X_train oraz etykietach binarnych y_train_0, które oznaczają próbki reprezentujące cyfrę 0.

from sklearn.linear_model import SGDClassifier

sgd_clf_0 = SGDClassifier(n_jobs=-1)
sgd_clf_0.fit(X_train, y_train_0)

#Policz dokładność ww. klasyfikatora na zbiorze uczącym oraz na zbiorze testującym.
#Zapisz wyniki jako listę (list(float)) w pliku Pickle o nazwie sgd_acc.pkl

import pickle

train_accuracy_0 = sgd_clf_0.score(X_train, y_train_0)
test_accuracy_0 = sgd_clf_0.score(X_test, y_test_0)
print("Train accuracy: ", train_accuracy_0, "\nTest accuracy: ", test_accuracy_0)

with open('sgd_acc.pkl', 'wb') as f:
    pickle.dump([train_accuracy_0, test_accuracy_0], f)

#Policz 3-punktową walidację krzyżową dokładności (accuracy) modelu dla zbioru uczącego. Zapisz
#wynik jako tablicę (ndarray(3,)) w pliku Pickle o nazwie sgd_cva.pkl.

from sklearn.model_selection import cross_val_score
score_0 = cross_val_score(sgd_clf_0, X_train, y_train_0,cv=3, scoring="accuracy", n_jobs=-1)
print("Cross validation score: ", score_0)

# save to pickle
with open('sgd_cva.pkl', 'wb') as f:
    pickle.dump(np.array(score_0), f)

#zad5

#Użyj klasyfikatora Stochastic Gradient Descent do klasyfikacji wszystkich cyfr.
#Utwórz macierz błędów dla zbioru testującego i zapisz ją jako tablicę (ndarray(10, 10)) w pliku
#Pickle o nazwie sgd_cmx.pkl.

sgd_clf = SGDClassifier()
sgd_clf.fit(X_train, y_train)

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
y_train_pred = sgd_clf.predict(X_train)
c_mx = confusion_matrix(y_train, y_train_pred)
print(c_mx)

with open('sgd_cmx.pkl', 'wb') as f:
    pickle.dump(c_mx, f)

y_test_pred = sgd_clf.predict(X_test)
cmx = confusion_matrix(y_test, y_test_pred)
print(cmx)