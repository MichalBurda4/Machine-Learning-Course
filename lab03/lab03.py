# -*- coding: utf-8 -*-
"""lab03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NgB5Qrc2NSa2-KAv7uQ9Y6mm2tfmYbGc

**1 Cel/Zakres**

*   Przeporowadzenie regresji.
*   Por贸wnanie regresor贸w.
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import SGDClassifier
import pickle
import numpy as np

"""**2 Przygotowanie danych**

Dany jest zbi贸r argument贸w (X) oraz wartoci (y) funkcji jednej zmiennej w postaci obiektu
DataFrame df:
"""

size = 300
X = np.random.rand(size)*5-2.5
w4, w3, w2, w1, w0 = 1, 2, 1, -4, 2
y = w4*(X**4) + w3*(X**3) + w2*(X**2) + w1*X + w0 + np.random.randn(size)*8-4
df = pd.DataFrame({'x': X, 'y': y})
df.to_csv('dane_do_regresji.csv',index=None)
df.plot.scatter(x='x',y='y')

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #random_state - ziarno liczb pseudolosowych

#przeksztacenie wymiar贸w zmiennych X_train, X_test, y_train i y_test.
X_train = X_train.reshape(-1,1)
X_test = X_test.reshape(-1,1)
y_train = y_train.reshape(-1,1)
y_test = y_test.reshape(-1,1)

print("Rozmiary zbior贸w:")
print("Zbi贸r uczcy (X_train):", X_train.shape)
print("Zbi贸r testowy (X_test):", X_test.shape)

#Zbiory s podzielone w skali 80:20

"""**3 Regresja**
1. Wykonaj nastpujce regresje na ww. zbiorze:
1
1. liniow,
2. KNN, dla  = 3 oraz  = 5,
3. wielomianow 2, 3, 4 i 5 rzdu.
2. Przeanalizuj dziaanie ka偶dej z otrzymanych funkcji regresyjnych. Por贸wnaj ich przebiegi z
rozkadem zbioru danych.
3. Zapisz w osobnym DataFrame wartoci MSE dla zbior贸w uczcych i testujcych dla ww.
regresor贸w; kolumny: train_mse, test_mse, wiersze: lin_reg, knn_3_reg, knn_5_reg,
poly_2_reg, poly_3_reg, poly_4_reg, poly_5_reg. Zapisz ww. DataFrame do pliku Pickle
o nazwie: mse.pkl
7 pkt
4. Zapisz do pliku Pickle o nazwie reg.pkl list krotek zawierajcych obiekty reprezentujce
regresory: [(lin_reg, None), (knn_3_reg, None), (knn_5_reg, None), (poly_2_reg,
poly_feature_2), (poly_3_reg, poly_feature_3), (poly_4_reg, poly_feature_4),
(poly_5_reg, poly_feature_5)]

**Regresja liniowa**
"""

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)
print(lin_reg.intercept_, lin_reg.coef_)

"""**KNN**"""

from sklearn.neighbors import KNeighborsRegressor
import sklearn.neighbors

knn_reg_3 = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)
knn_reg_3.fit(X_train, y_train)
print(knn_reg_3.predict([[0]]))

knn_reg_5 = sklearn.neighbors.KNeighborsRegressor(n_neighbors=5)
knn_reg_5.fit(X_train, y_train)
print(knn_reg_5.predict([[0]]))

"""**Wielomianow**"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

from sklearn.preprocessing import PolynomialFeatures
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly_2 = poly_features.fit_transform(X_train)
lin_reg_poly_2 = LinearRegression()
lin_reg_poly_2.fit(X_poly_2, y_train)
print("Regresja wielomianowa stopnia 2: ", lin_reg_poly_2.intercept_, lin_reg_poly_2.coef_)

poly_features_3 = PolynomialFeatures(degree=3, include_bias=False)
X_poly_3 = poly_features_3.fit_transform(X_train)
lin_reg_poly_3 = LinearRegression()
lin_reg_poly_3.fit(X_poly_3, y_train)
print("Regresja wielomianowa stopnia 3: ", lin_reg_poly_3.intercept_, lin_reg_poly_3.coef_)

poly_features_4 = PolynomialFeatures(degree=4, include_bias=False)
X_poly_4 = poly_features_4.fit_transform(X_train)
lin_reg_poly_4 = LinearRegression()
lin_reg_poly_4.fit(X_poly_4, y_train)
print("Regresja wielomianowa stopnia 4: ", lin_reg_poly_4.intercept_, lin_reg_poly_4.coef_)

poly_features_5 = PolynomialFeatures(degree=5, include_bias=False)
X_poly_5 = poly_features_5.fit_transform(X_train)
lin_reg_poly_5 = LinearRegression()
lin_reg_poly_5.fit(X_poly_5, y_train)
print("Regresja wielomianowa stopnia 5: ", lin_reg_poly_5.intercept_, lin_reg_poly_5.coef_)

y_pred_lin = lin_reg.predict(X_test) # Generuje prognozy dla danych testowych za pomoc modelu regresji liniowej.
y_pred_knn_3 = knn_reg_3.predict(X_test) # Generuje prognozy dla danych testowych za pomoc modelu KNN z parametrem k=3.
y_pred_knn_5 = knn_reg_5.predict(X_test)
y_pred_poly_2 = lin_reg_poly_2.predict(poly_features.transform(X_test))
y_pred_poly_3 = lin_reg_poly_3.predict(poly_features_3.transform(X_test))
y_pred_poly_4 = lin_reg_poly_4.predict(poly_features_4.transform(X_test))
y_pred_poly_5 = lin_reg_poly_5.predict(poly_features_5.transform(X_test))



#Wyjresy
plt.scatter(X_test, y_test, label='Dane testowe')
plt.scatter(X_test, y_pred_lin, label='Regresja liniowa')
plt.scatter(X_test, y_pred_knn_3, label='Regresja KNN dla k=3')
plt.scatter(X_test, y_pred_knn_5, label='Regresja KNN dla k=5')
plt.scatter(X_test, y_pred_poly_2, label='Regresja wielomianowa dla stopnia 2')
plt.scatter(X_test, y_pred_poly_3, label='Regresja wielomianowa dla stopnia 3')
plt.scatter(X_test, y_pred_poly_4, label='Regresja wielomianowa dla stopnia 4')
plt.scatter(X_test, y_pred_poly_5, label='Regresja wielomianowa dla stopnia 5')


plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error

#Zapisz ww. DataFrame do pliku Pickle
#o nazwie: mse.pkl
df_mse = pd.DataFrame({'train_mse': [mean_squared_error(y_train, lin_reg.predict(X_train)),
                                     mean_squared_error(y_train, knn_reg_3.predict(X_train)), mean_squared_error(y_train, knn_reg_5.predict(X_train)),
                                     mean_squared_error(y_train, lin_reg_poly_2.predict(poly_features.transform(X_train))),
                                     mean_squared_error(y_train, lin_reg_poly_3.predict(poly_features_3.transform(X_train))),
                                     mean_squared_error(y_train, lin_reg_poly_4.predict(poly_features_4.transform(X_train))),
                                     mean_squared_error(y_train, lin_reg_poly_5.predict(poly_features_5.transform(X_train)))],

                       'test_mse' : [mean_squared_error(y_test, lin_reg.predict(X_test)),
                                     mean_squared_error(y_test, knn_reg_3.predict(X_test)), mean_squared_error(y_test, knn_reg_5.predict(X_test)),
                                     mean_squared_error(y_test, lin_reg_poly_2.predict(poly_features.transform(X_test))),
                                     mean_squared_error(y_test, lin_reg_poly_3.predict(poly_features_3.transform(X_test))),
                                     mean_squared_error(y_test, lin_reg_poly_4.predict(poly_features_4.transform(X_test))),
                                     mean_squared_error(y_test, lin_reg_poly_5.predict(poly_features_5.transform(X_test)))]},

                        index=['lin_reg', 'knn_3_reg', 'knn_5_reg', 'poly_2_reg', 'poly_3_reg', 'poly_4_reg', 'poly_5_reg'])
df_mse.to_pickle('mse.pkl')
df_mse

#7
list_of_models = [(lin_reg, None), (knn_reg_3, None), (knn_reg_5, None), (lin_reg_poly_2, poly_features), (lin_reg_poly_3, poly_features_3), (lin_reg_poly_4, poly_features_4), (lin_reg_poly_5, poly_features_5)]

with open('reg.pkl', 'wb') as f:
    pickle.dump(list_of_models, f)